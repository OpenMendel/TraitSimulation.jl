{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TraitSimulation explores GPU computing in Julia\n",
    "\n",
    "Author: Sarah Ji\n",
    "\n",
    "In this notebook, we will explore some GPU capabilities of the Julia language in the CuArrays package, and present the potential for users to extend the functions in TraitSimulation.jl to accomodate advances in GPU computing. Although GPU computing is still under active development, it is fruitful for researchers to be aware of the most modern computing technologies available to users through open source options. \n",
    "\n",
    "We will first present the major bottle necks of the simulation algorithm and benchmark the optimized code (using BLAS) on CPU vs. on GPU. Then we will simulate the symmetric Bivariate trait using TraitSimulation on CPU first, then GPU for comparison. \n",
    "\n",
    "1. First the simulation algorithm first performs the cholesky factors of the variance/covariance matrices and stores them using the @vc macro.\n",
    "2. Then we transform the standard normal matrix using the cholesky factors above\n",
    "\n",
    "Note useres with many variance components or extremely large number of subjects may benefit most from exploring GPU. \n",
    "Additionally, since the default setting in the notebook is 1 thread, so I will only compare the unthreaded CPU code vs. the GPU code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.4.0\n",
      "Commit b8e9a9ecc6 (2020-03-21 16:36 UTC)\n",
      "Platform Info:\n",
      "  OS: Linux (x86_64-pc-linux-gnu)\n",
      "  CPU: Intel(R) Core(TM) i9-9920X CPU @ 3.50GHz\n",
      "  WORD_SIZE: 64\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-8.0.1 (ORCJIT, skylake)\n"
     ]
    }
   ],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check available devices on this machine and show their capability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capability(device) = v\"7.5.0\"\n"
     ]
    }
   ],
   "source": [
    "using CuArrays, CUDAdrv\n",
    "using CuArrays.CURAND\n",
    "\n",
    "for device in CuArrays.devices()\n",
    "    @show capability(device)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use simulated data and include the exploratory TraitSimulation on GPU code, in the file `exploring_gpu_simulation.jl`. We encourage users with the right NVIDIA GPU machine to explore these options for themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"/home/sarahji/TraitSimulation.jl/src/exploring_gpu_simulation.jl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "using GLM, LinearAlgebra, Random, BenchmarkTools\n",
    "using SnpArrays, Statistics\n",
    "\n",
    "Random.seed!(1234)\n",
    "\n",
    "function generateSPDmatrix(n)\n",
    "    A = rand(n)\n",
    "    m = 0.5 * (A * A')\n",
    "    PDmat = m + (n * Diagonal(ones(n)))\n",
    "end\n",
    "\n",
    "\n",
    "function generateRandomVCM(n::Int64, p::Int64, d::Int64, m::Int64)\n",
    "    # n-by-p design matrix\n",
    "    X = randn(n, p)\n",
    "\n",
    "    # p-by-d mean component regression coefficient for each trait\n",
    "    B = rand(p, d)\n",
    "\n",
    "    V = ntuple(x -> zeros(n, n), m)\n",
    "    for i = 1:m-1\n",
    "      copy!(V[i], generateSPDmatrix(n))\n",
    "    end\n",
    "    copy!(V[end], Diagonal(ones(n))) # last covarianec matrix is identity\n",
    "\n",
    "    # a tuple of m d-by-d variance component parameters\n",
    "    Σ = ntuple(x -> zeros(d, d), m)\n",
    "    for i in 1:m\n",
    "      copy!(Σ[i], generateSPDmatrix(d))\n",
    "    end\n",
    "    return(X, B, Σ, V)\n",
    "end\n",
    "\n",
    "\n",
    "n = 5000 # number of people\n",
    "p = 3   # number of fixed effects\n",
    "d = 10   # number of traits\n",
    "m = 10   # number of variance components\n",
    "\n",
    "X, β, Σ, V = generateRandomVCM(n, p, d, m);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Cholesky Decomposition of Variance Components\n",
    "\n",
    "The major bottleneck in the simulation process is the cholesky decomposition of the variance covariance matrices (variance components). We note that if users have many variance components will benefit from having the GPU option available to their software. \n",
    "\n",
    "First we compute the Cholesky Decomposition of a single nxn matrix, V[1], then we use the @vc macro and make a GPU alternative to compare.\n",
    "\n",
    "We see that for a 5000 by 5000 matrix, the GPU code is more than 30x faster than the cholesky decomposition computed on CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cholesky on CPU for a single variance component (n x n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size(V[1]) = (5000, 5000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  190.74 MiB\n",
       "  allocs estimate:  6\n",
       "  --------------\n",
       "  minimum time:     277.191 ms (0.00% GC)\n",
       "  median time:      292.412 ms (0.00% GC)\n",
       "  mean time:        326.911 ms (1.62% GC)\n",
       "  maximum time:     769.881 ms (4.69% GC)\n",
       "  --------------\n",
       "  samples:          16\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cholesky on CPU for a single trait\n",
    "@show size(V[1])\n",
    "@benchmark cholesky((Symmetric($V[1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cholesky on GPU for a single variance component (n x n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.959381 seconds (1.94 M allocations: 191.373 MiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  4.00 KiB\n",
       "  allocs estimate:  118\n",
       "  --------------\n",
       "  minimum time:     10.111 ms (0.00% GC)\n",
       "  median time:      10.289 ms (0.00% GC)\n",
       "  mean time:        10.339 ms (0.34% GC)\n",
       "  maximum time:     14.302 ms (19.20% GC)\n",
       "  --------------\n",
       "  samples:          484\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time V1_gpu = CuArray{Float32}(V[1]) # Move the Variance Covariance Matrix V from CPU to GPU environment\n",
    "@benchmark cholesky((Symmetric($V1_gpu)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We made this @vc macro to provide a more flexible input option for users, but we see that there is a cost for comfort!\n",
    "\n",
    "The single cholesky is about 30 fold speed up but using the macro its only about 6x \n",
    "So we note that for maximum efficiency, when users have large datasets, they can bypass this and just store the cholesky factors necessary to perform the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  381.47 MiB\n",
       "  allocs estimate:  25\n",
       "  --------------\n",
       "  minimum time:     1.609 s (0.31% GC)\n",
       "  median time:      1.801 s (3.48% GC)\n",
       "  mean time:        2.100 s (3.78% GC)\n",
       "  maximum time:     2.890 s (5.90% GC)\n",
       "  --------------\n",
       "  samples:          3\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc_cpu = @vc Σ[1] ⊗ V[1] + Σ[2] ⊗ V[2] # make the vc object with just 2 variance components\n",
    "trait = VCMTrait(X, β, [Σ...], [V...]) # make the trait object with all m = 10 variance components.\n",
    "\n",
    "@benchmark vc_cpu = @vc $Σ[1] ⊗ $V[1] + $Σ[2] ⊗ $V[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  16.78 KiB\n",
       "  allocs estimate:  497\n",
       "  --------------\n",
       "  minimum time:     274.375 ms (0.00% GC)\n",
       "  median time:      277.834 ms (0.00% GC)\n",
       "  mean time:        292.647 ms (0.22% GC)\n",
       "  maximum time:     350.880 ms (0.83% GC)\n",
       "  --------------\n",
       "  samples:          18\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc_gpu = @vc_gpu Σ[1] ⊗ V[1] + Σ[2] ⊗ V[2]\n",
    "@benchmark vc_gpu = @vc_gpu $Σ[1] ⊗ $V[1] + $Σ[2] ⊗ $V[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Matrix Normal Transformation by Cholesky Factors \n",
    "\n",
    "Each variance component will require it's own simulation from the standard normal distribution and the appropriate transformations by the cholesky factors of the row and column variances. \n",
    "\n",
    "We saw separately that the cholesky decomposition is sped up by an order of magnitude on GPU vs. on CPU in step 1.\n",
    "Now, to complete the simulation we will perform step 2 to multiply on the left and right to transform the simulated trait to have the desired covariance.\n",
    "\n",
    "There is a 30x fold speed up in JUST transforming the matrix normal using GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     19.655 ms (0.00% GC)\n",
       "  median time:      20.967 ms (0.00% GC)\n",
       "  mean time:        21.233 ms (0.00% GC)\n",
       "  maximum time:     23.723 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          236\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function cpu_single_vc(trait, CholΣ, CholV)\n",
    "    randn!(trait.Z)\n",
    "    BLAS.trmm!('L', 'U', 'T', 'N', 1.0, CholV, trait.Z)\n",
    "    BLAS.trmm!('R', 'U', 'N', 'N', 1.0, CholΣ, trait.Z)\n",
    "    trait.Z\n",
    "end\n",
    "\n",
    "CholΣ = trait.vc[1].CholΣ # grab the cholesky factors of Σ (dxd) from step 1\n",
    "CholV = trait.vc[1].CholV # grab the cholesky factor of V (nxn) from step 1\n",
    "\n",
    "@benchmark cpu_single_vc($trait, $CholΣ, $CholV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  784 bytes\n",
       "  allocs estimate:  29\n",
       "  --------------\n",
       "  minimum time:     16.213 μs (0.00% GC)\n",
       "  median time:      1.061 ms (0.00% GC)\n",
       "  mean time:        1.010 ms (0.08% GC)\n",
       "  maximum time:     10.271 ms (38.50% GC)\n",
       "  --------------\n",
       "  samples:          4946\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gpu_single_vc(Z_d, CholΣ, CholV)\n",
    "    randn!(Z_d)\n",
    "    CuArrays.CUBLAS.trmm!('L', 'U', 'T', 'N', 1.0, CholV, Z_d, similar(Z_d))\n",
    "    CuArrays.CUBLAS.trmm!('R', 'U', 'N', 'N', 1.0, CholΣ, Z_d, similar(Z_d))\n",
    "    Z_d\n",
    "end\n",
    "\n",
    "Z_d = CuArray{Float64}(trait.Z)\n",
    "CholΣ_gpu = vc_gpu[1].CholΣ # grab the cholesky factors of Σ (dxd) from step 1\n",
    "CholV_gpu = vc_gpu[1].CholV # grab the cholesky factor of V (nxn) from step 1\n",
    "\n",
    "@benchmark gpu_single_vc($Z_d, $CholΣ_gpu, $CholV_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform TraitSimulation\n",
    "\n",
    "Here we just compare a single simulation on CPU vs. on GPU. \n",
    "This is the function that is continuously called in the power calculation. It writes over the field Y, the simulated results after aggregating the simulation results of the m variance components. (random effects) \n",
    "\n",
    "For users who wish to do multiple simulation runs simultaenously, we recommmend to set the machinery to use threading. Users can check using the command: `Threads.nthreads()` to ensure multi-threading is on. [TraitSimulation](https://github.com/OpenMendel/TraitSimulation.jl/blob/master/src/TraitSimulation.jl#L188) will automatically use the Threading option for multiple traitsimulation. To set the number of threads, users should follow the documentation on [Threads.jl](https://docs.julialang.org/en/v1/base/multi-threading/) and ensure before starting julia to specify the desired number of threads.\n",
    "\n",
    "For users who are using the Threading option and are seeing some variation in the benchmarking results, make sure that the julia number of threads and the BLAS number of threads are not confusing one another and specify the commmand: `LinearAlgebra.BLAS.set_num_threads(1)` to make simulations more consistent.\n",
    "\n",
    "\n",
    "1. First we see the simulation for a single variance component\n",
    "2. Then we see the simulation for the entire variance component set in trait.vc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TraitSimulation for a Single Variance Component\n",
    "\n",
    "We see this is roughly 20 times faster on GPU than on CPU for a single $V_{n \\times n}, \\Sigma_{d \\times d}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     27.357 ms (0.00% GC)\n",
       "  median time:      32.112 ms (0.00% GC)\n",
       "  mean time:        40.311 ms (0.00% GC)\n",
       "  maximum time:     83.568 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          124\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark TraitSimulation.simulate_matrix_normal!($trait.Z, $vc_cpu[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  784 bytes\n",
       "  allocs estimate:  29\n",
       "  --------------\n",
       "  minimum time:     17.176 μs (0.00% GC)\n",
       "  median time:      1.060 ms (0.00% GC)\n",
       "  mean time:        1.009 ms (0.00% GC)\n",
       "  maximum time:     1.468 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          4950\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_d = CuArray{Float64}(trait.Z)\n",
    "@benchmark simulate_matrix_normal_gpu!($Z_d, $vc_gpu[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TraitSimulation for the set of m Variance Components\n",
    "\n",
    "We see above that the simulation for just a single variance component is roughly 30 times faster. \n",
    "\n",
    "Since we have m = 10 variance components in our model, we see that in this case the simulation on GPU is 100x faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  0 bytes\n",
       "  allocs estimate:  0\n",
       "  --------------\n",
       "  minimum time:     200.812 ms (0.00% GC)\n",
       "  median time:      257.338 ms (0.00% GC)\n",
       "  mean time:        266.100 ms (0.00% GC)\n",
       "  maximum time:     626.675 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          19\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = zero(trait.μ)\n",
    "@benchmark TraitSimulation.VCM_trait_simulation($Y, $trait.Z, $trait.μ, $trait.vc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  10.67 KiB\n",
       "  allocs estimate:  283\n",
       "  --------------\n",
       "  minimum time:     67.968 μs (0.00% GC)\n",
       "  median time:      2.134 ms (0.00% GC)\n",
       "  mean time:        2.056 ms (0.00% GC)\n",
       "  maximum time:     2.361 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          2430\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_d = zeros(CuArray{Float32}, size(trait.Z))\n",
    "μ_d = zeros(CuArray{Float32}, size(trait.μ))\n",
    "@benchmark VCM_trait_simulation_gpu($Y_d, $μ_d, $Z_d, $vc_gpu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.4.0",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
